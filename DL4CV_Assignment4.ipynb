{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCYZMNB89n6C"
   },
   "source": [
    "**Welcome to Assignment 4 on Deep Learning for Computer Vision.**\n",
    "\n",
    "This assignment consists of three parts. Part-1 is based on the content you learned in Week-7 of course and Part-2 is based on the content you learned in Week-8 of the course. \n",
    "\n",
    "\n",
    "#### **Instructions**\n",
    "1. Use Python 3.x to run this notebook\n",
    "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.\n",
    "you should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
    "3. Read documentation of each function carefully.\n",
    "4. All the Best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9ZO0lUg9vnm"
   },
   "source": [
    "# Part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtVEfKH7dqbu"
   },
   "source": [
    "## Triplet loss:\n",
    "\n",
    "In this question you will implement triplet loss for MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yEOowOYw9Uxo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from PIL import Image\n",
    "import timeit\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "## Please DONOT remove these lines. \n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)\n",
    "########################\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "#### YOUR CODE STARTS HERE ####\n",
    "# Check availability of GPU and set the device accordingly\n",
    "device =  \"cuda\" if cuda else \"cpu\"\n",
    "#### YOUR CODE ENDS HERE ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n9TiTCF5CXCQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Prepare dataset\n",
    "train_dataset = MNIST('../data/MNIST', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "test_dataset = MNIST('../data/MNIST', train=False, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ]))\n",
    "n_classes = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8XloNEneiOa"
   },
   "source": [
    "###Create dataset for Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_BulQt1C_FJD"
   },
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This program returns anchor, positive and negative sample for training \n",
    "    Creates fixed triplets for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mnist_dataset):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.train = self.mnist_dataset.train\n",
    "        self.transform = self.mnist_dataset.transform\n",
    "        # prepare labels and data for extracting positive and negative samples during training\n",
    "        if self.train:\n",
    "            self.train_labels = self.mnist_dataset.train_labels\n",
    "            self.train_data = self.mnist_dataset.train_data\n",
    "            self.labels_set = set(self.train_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.train_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # Refering to the above code where we prepared labels and data for testing, please prepare test samples\n",
    "        else:\n",
    "            self.test_labels = self.mnist_dataset.test_labels\n",
    "            self.test_data = self.mnist_dataset.test_data\n",
    "            self.labels_set = set(self.test_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.test_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "       #### YOUR CODE ENDS HERE ####\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            triplets = [[i,\n",
    "                         random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
    "                         random_state.choice(self.label_to_indices[\n",
    "                                                 np.random.choice(\n",
    "                                                     list(self.labels_set - set([self.test_labels[i].item()]))\n",
    "                                                 )\n",
    "                                             ])\n",
    "                         ]\n",
    "                        for i in range(len(self.test_data))]\n",
    "            self.test_triplets = triplets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "          #### YOUR CODE STARTS HERE ####\n",
    "            # assign train_data[index] to anchor and train_label[index] item() to label1 \n",
    "            anchor, label1 = self.train_data[index] , self.train_labels[index].item()\n",
    "          #### YOUR CODE ENDS HERE ####\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
    "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "            positive = self.train_data[positive_index]\n",
    "            negative = self.train_data[negative_index]\n",
    "        else:\n",
    "           #### YOUR CODE STARTS HERE ####\n",
    "             # assign test_triplets[index][0] to anchor, test_triplets[index][1] as positive sample and test_triplets[index][2]\n",
    "            anchor = self.test_data[self.test_triplets[index][0]]\n",
    "            positive = self.test_data[self.test_triplets[index][1]]\n",
    "            negative = self.test_data[self.test_triplets[index][2]]\n",
    "           #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "        anchor = Image.fromarray(anchor.numpy(), mode='L')\n",
    "        positive = Image.fromarray(positive.numpy(), mode='L')\n",
    "        negative = Image.fromarray(negative.numpy(), mode='L')\n",
    "        if self.transform is not None:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "        return (anchor, positive, negative), []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0nsYlOiuDLAw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE STARTS HERE ####\n",
    "# define the training and test sets\n",
    "# use TripletDataset\n",
    "# pass train_dataset for triplet_train_dataset and test_datset for triplet_test_dataset\n",
    "triplet_train_dataset = TripletDataset(train_dataset)\n",
    "triplet_test_dataset = TripletDataset(test_dataset)\n",
    "#### YOUR CODE ENDS HERE ####\n",
    "batch_size = 128\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IuBgY8H3ABps"
   },
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # Define a sequential block as per the instructions below:\n",
    "        # Build three blocks with each block containing: Conv->PReLU->Maxpool2d layers\n",
    "        # Three conv layers should have 16, 32, 64 output channels respectively\n",
    "        # Use convolution kernel size 3\n",
    "        # For maxpool use a kernel size of 2 and stride of 2\n",
    "\n",
    "        self.convnet = nn.Sequential( nn.Conv2d(1,16,3),\n",
    "                                      nn.PReLU(),\n",
    "                                      nn.MaxPool2d(2,stride=2),\n",
    "                                      nn.Conv2d(16,32,3),\n",
    "                                      nn.PReLU(),\n",
    "                                      nn.MaxPool2d(2,stride=2),\n",
    "                                      nn.Conv2d(32,64,3),\n",
    "                                      nn.PReLU(),\n",
    "                                      nn.MaxPool2d(2,stride=2)\n",
    "                                     )\n",
    "\n",
    "\n",
    "        # Define linear->PReLU->linear->PReLU->linear\n",
    "        # The first two linear layers should have 256 and 128 output nodes\n",
    "        # The final FC layer should have 2 nodes\n",
    "        self.fc = nn.Sequential(nn.Linear(64*1*1,256),\n",
    "                                nn.PReLU(),\n",
    "                                nn.Linear(256,128),\n",
    "                                nn.PReLU(),\n",
    "                                nn.Linear(128,2))\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "    def forward(self, x):\n",
    "      #### YOUR CODE STARTS HERE ####\n",
    "        # Define the forward pass, convnet -> fc\n",
    "        output = self.convnet(x)\n",
    "        output = output.view(-1,64*1*1)\n",
    "        output = self.fc(output)\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ywj6s1xrAiqi"
   },
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "      #### YOUR CODE STARTS HERE ####\n",
    "      # Call the embedding network for anchor,positive and negative samples (x1,x2,x3)\n",
    "        output1 = self.embedding_net.forward(x1)\n",
    "        output2 = self.embedding_net.forward(x2)\n",
    "        output3 = self.embedding_net.forward(x3)\n",
    "      #### YOUR CODE ENDS HERE ####\n",
    "        return output1, output2, output3\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nxDUKVD1_JqE"
   },
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss\n",
    "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return ((x1 - x2).pow(2).sum(1)).pow(0.5)\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "      #### YOUR CODE STARTS HERE ####\n",
    "        # calculate the eucledian distance between anchor and positive sample\n",
    "        #positive_distance = torch.cdist(anchor,positive)\n",
    "        positive_distance = self.calc_euclidean(anchor, positive)\n",
    "        # calculate the eucledian distance between anchor and negative sample\n",
    "        #negative_distance = torch.cdist(anchor,negative)\n",
    "        negative_distance = self.calc_euclidean(anchor, negative)\n",
    "      #### YOUR CODE ENDS HERE #### \n",
    "        losses = F.relu(positive_distance - negative_distance + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ppTNLyiPDpqn"
   },
   "outputs": [],
   "source": [
    "margin = 1.\n",
    "embedding_net = EmbeddingNet()\n",
    "model = TripletNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(margin)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mjM2ofUage9X"
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, loss_fn, optimizer, cuda):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target if len(target) > 0 else None\n",
    "        if not type(data) in (tuple, list):\n",
    "            data = (data,)\n",
    "        if cuda:\n",
    "            data = tuple(d.cuda() for d in data)\n",
    "            if target is not None:\n",
    "                target = target.cuda()\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*data)\n",
    "\n",
    "        if type(outputs) not in (tuple, list):\n",
    "            outputs = (outputs,)\n",
    "\n",
    "        loss_inputs = outputs\n",
    "        if target is not None:\n",
    "            target = (target,)\n",
    "            loss_inputs += target\n",
    "\n",
    "        loss_outputs = loss_fn(*loss_inputs)\n",
    "        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss /= (batch_idx + 1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8fSErkFDgf5W"
   },
   "outputs": [],
   "source": [
    "def test_epoch(val_loader, model, loss_fn, cuda):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            target = target if len(target) > 0 else None\n",
    "            if not type(data) in (tuple, list):\n",
    "                data = (data,)\n",
    "            if cuda:\n",
    "                data = tuple(d.cuda() for d in data)\n",
    "                if target is not None:\n",
    "                    target = target.cuda()\n",
    "\n",
    "            outputs = model(*data)\n",
    "\n",
    "            if type(outputs) not in (tuple, list):\n",
    "                outputs = (outputs,)\n",
    "            loss_inputs = outputs\n",
    "            if target is not None:\n",
    "                target = (target,)\n",
    "                loss_inputs += target\n",
    "\n",
    "            loss_outputs = loss_fn(*loss_inputs)\n",
    "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            \n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "M1cPjWocgycA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/2. Training: Average loss: 0.1939\n",
      "\n",
      "Epoch: 1/2. Testing: Average loss: 0.1202\n",
      "\n",
      "Epoch: 2/2. Training: Average loss: 0.0940\n",
      "\n",
      "Epoch: 2/2. Testing: Average loss: 0.0865\n"
     ]
    }
   ],
   "source": [
    "n_epochs=2\n",
    "for epoch in range(n_epochs):\n",
    "        train_loss= train_epoch(triplet_train_loader, model, loss_fn, optimizer, cuda)\n",
    "        print('\\nEpoch: {}/{}. Training: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss))\n",
    "        test_loss= test_epoch(triplet_test_loader, model, loss_fn, cuda)\n",
    "        test_loss /= len(triplet_test_loader)\n",
    "        print('\\nEpoch: {}/{}. Testing: Average loss: {:.4f}'.format(epoch + 1, n_epochs,test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVHDOS1HCHXo"
   },
   "source": [
    "## Question 1:\n",
    "\n",
    "What is the average test loss obtained after training MNIST on triplet loss for two epochs?\n",
    "\n",
    "1.   0.5487\n",
    "2.   0.1039\n",
    "3.   0.8735\n",
    "4.   0.9924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAFI5JbWFFnI"
   },
   "source": [
    "Write code to calculate IoU between aligned predicted bounding-boxes bbox_p and ground-truth bounding-boxes bbox_gt. Assume a co-ordinate system that has origin (0,0) at the upper-left corner of the image, and to the right and down are +ve directions of x-axis and y-axis respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "HuoAMvp7FEU3"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(bbox_p, bbox_gt):\n",
    "    #input: bbox_p and bbox_gt are 4 dimensional tensors\n",
    "    #output: ious (N,) vector\n",
    "    \n",
    "    #### YOUR CODE STARTS HERE ####\n",
    "    # write code to compute the IoU between the bounding boxes\n",
    "    # find the top-left point of intersection of predicted and ground truth bounding boxes\n",
    "    #Hint : if the top left points of box1=(10,20) and box2=(30,10) the point of interestion is (30,20)\n",
    "    xA = max(bbox_p[0],bbox_gt[0])\n",
    "    yA = max(bbox_p[1],bbox_gt[1])\n",
    "    # find the bottom-right point of intersection of predicted and ground truth bounding boxes\n",
    "    #Hint : if the bottom-right points of box1=(20,30) and box2=(10,40) the point of interestion is (10,30)\n",
    "    xB = min(bbox_p[2],bbox_gt[2])\n",
    "    yB = min(bbox_p[3],bbox_gt[3])\n",
    "    #Find the width of overlapping region\n",
    "    # Hint: Try to imagine a rectangle whose top left corner is (xA,yA) and bottom right corner is (xB,yB)\n",
    "    overlap_width= yB-yA\n",
    "    if overlap_width<0:\n",
    "        overlap_width=0\n",
    "   #Find the height of overlapping region\n",
    "    overlap_ht= xB-xA\n",
    "    if overlap_ht<0:\n",
    "        overlap_ht=0\n",
    "    #Find the area of overlapping region\n",
    "    interArea = overlap_width*overlap_ht\n",
    "    box_width=bbox_p[2] - bbox_p[0]\n",
    "    box_ht=bbox_p[3] - bbox_p[1]\n",
    "    bbox_pArea = box_width*box_ht\n",
    "    bbox_gtArea = (bbox_gt[2] - bbox_gt[0] ) * (bbox_gt[3] - bbox_gt[1] )\n",
    "    #Calculate IOU\n",
    "    # you can refer to slide number 13 of week7_part1\n",
    "    # A union B= A+B-(A intersection B)\n",
    "    iou = interArea / float(bbox_pArea + bbox_gtArea - interArea)\n",
    "    #### YOUR CODE ENDS HERE ####\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CxEPYz2qJMxH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766543144520911\n"
     ]
    }
   ],
   "source": [
    "bbox_p=[45, 66, 203, 112]\n",
    "bbox_gt=[54, 66, 198, 114]\n",
    "print(calculate_iou(bbox_p, bbox_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_53wKATVMM90"
   },
   "source": [
    "## Question 2:\n",
    "\n",
    "What is the Intersection Over Union value (rounded to three digits) for \n",
    "\n",
    "\n",
    "predicted bounding box=[45, 66, 203, 112]\n",
    "\n",
    "\n",
    "ground truth bounding box=[54, 66, 198, 114]\n",
    "\n",
    "1.   0.456\n",
    "2.   0.589\n",
    "3.   0.877\n",
    "4.   0.253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnIJ8jC_MNIC"
   },
   "source": [
    "We will implement Focal Loss by extending the nn class of pytorch. Given the predicted scoress and one-hot encoding of actual labels, it should return the loss value. Arxiv link to the research paper that proposed focal loss is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RD_VAILzKSwT"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    'Focal Loss - https://arxiv.org/abs/1708.02002'\n",
    "\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, pred_logits, target):\n",
    "        pred = pred_logits.sigmoid()\n",
    "        ce = F.binary_cross_entropy_with_logits(pred_logits, target, reduction='none')\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # Refer equation (2) of the focal loss paper to find pt\n",
    "        pt = torch.where(target==1, pred, 1-pred)\n",
    "        # Refer to equation (5) of the focal loss paper to find F_loss\n",
    "        #assume ce=log(pt), alpha=self.alpha and gamma=self.gamma\n",
    "        F_loss= -self.alpha*((1-pt)**self.gamma)*ce\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        return torch.mean(F_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "92yw-gHHXjnf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assume predicted is the predicted score\n",
    "predicted_score=torch.tensor([[2.8189, 2.8334, 2.8816, 2.8754, 2.7178, 2.9008, 2.9511, 2.9113],\n",
    "  [3.0138, 3.1324, 3.1453, 3.1421, 3.0259, 3.0763, 2.9275, 3.0247],\n",
    "  [3.1808, 3.2000, 3.2535, 3.3548, 3.2533, 3.2937, 3.2101, 3.2429]])\n",
    "#One hot encoding of the actual labels\n",
    "actual_label=torch.tensor([[0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "        [0., 0., 0., 1., 0., 0., 0., 0.]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Y9a_osCfXiEq"
   },
   "outputs": [],
   "source": [
    "# create an object of FocalLoss\n",
    "focal_loss=FocalLoss(alpha=2, gamma=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2fpQo4hFYIGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.3208)\n"
     ]
    }
   ],
   "source": [
    " #### YOUR CODE STARTS HERE ####\n",
    "#Calculate focal loss between predicted_score and actual_label\n",
    "#Use the focal_loss object created above\n",
    "#Print the value\n",
    "loss = focal_loss.forward(predicted_score,actual_label)\n",
    "print(loss)\n",
    "#### YOUR CODE ENDS HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1870,  1.0845],\n",
      "        [-0.8132,  1.2791],\n",
      "        [-1.4758,  0.3695]]) tensor([[ 2.6829, -1.9958],\n",
      "        [ 0.6014,  0.9072],\n",
      "        [-0.6664, -0.7910]]) tensor([[ 0.1870,  1.0845],\n",
      "        [ 0.6014,  1.2791],\n",
      "        [-0.6664,  0.3695]])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.randn(3, 2)\n",
    "# y = torch.randn(3, 2)\n",
    "\n",
    "\n",
    "# z = torch.where(x > 0, x, y)\n",
    "# print(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ETDu_MjFqa-"
   },
   "source": [
    "## Question 3:\n",
    "\n",
    "What is the value of focal loss obtained above?\n",
    "\n",
    "1.   4.3208\n",
    "2.   9.6345\n",
    "3.   1.8743\n",
    "4.   8.2538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQx0XSwcXWkw"
   },
   "source": [
    "# Part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtNaqMjcX8Nn"
   },
   "source": [
    "Time series prediction using recurrent models. \n",
    "\n",
    "Use the airline-passengers.csv file for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "reH70kE4XgxA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "training_set = pd.read_csv('airline-passengers.csv')\n",
    "\n",
    "\n",
    "training_set = training_set.iloc[:,1:2].values\n",
    "\n",
    "plt.plot(training_set, label = 'Airline Passangers Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qo-Bn3vxGvD"
   },
   "source": [
    "## Prepare the training and testing dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZCFod5yYxQXt"
   },
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "training_data = sc.fit_transform(training_set)\n",
    "\n",
    "seq_length = 4\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "train_size = int(len(y) * 0.67)\n",
    "test_size = len(y) - train_size\n",
    "\n",
    "dataX = Variable(torch.Tensor(np.array(x)))\n",
    "dataY = Variable(torch.Tensor(np.array(y)))\n",
    "\n",
    "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
    "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
    "\n",
    "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
    "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-fbsv6_xVhu"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KC_5L1NIxUsR"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # define a lstm block with input size=input_size, hidden_size and num_layers, batch_first=True and a fc block with hidden_size as input and num_classes as output\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,hidden_size = self.hidden_size,num_layers=self.num_layers,batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size,self.num_classes)\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "    def forward(self, x):\n",
    "       \n",
    "        \n",
    "        # Define a forward function for the LSTM block\n",
    "        batch_size = x.size(0)\n",
    "        hidden_state = Variable(torch.zeros(\n",
    "            self.num_layers, batch_size, self.hidden_size))\n",
    "        \n",
    "        cell_state = hidden_state\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # Propagate input through LSTM\n",
    "        # pass the input, hidden state and cell_state\n",
    "        output, (hidden_out, cell_out) = self.lstm(x)\n",
    "        \n",
    "        #flatten hidden_out and pass it through fc layer\n",
    "        hidden_out =  hidden_out.view(-1,self.hidden_size)\n",
    "        \n",
    "        out = self.fc(hidden_out)\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQKOnThFxxuJ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vlj9F1Z6xxFR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.33608\n",
      "Epoch: 100, loss: 0.01524\n",
      "Epoch: 200, loss: 0.00730\n",
      "Epoch: 300, loss: 0.00293\n",
      "Epoch: 400, loss: 0.00265\n",
      "Epoch: 500, loss: 0.00243\n",
      "Epoch: 600, loss: 0.00223\n",
      "Epoch: 700, loss: 0.00205\n",
      "Epoch: 800, loss: 0.00191\n",
      "Epoch: 900, loss: 0.00180\n",
      "Epoch: 1000, loss: 0.00174\n",
      "Epoch: 1100, loss: 0.00170\n",
      "Epoch: 1200, loss: 0.00169\n",
      "Epoch: 1300, loss: 0.00168\n",
      "Epoch: 1400, loss: 0.00168\n",
      "Epoch: 1500, loss: 0.00167\n",
      "Epoch: 1600, loss: 0.00167\n",
      "Epoch: 1700, loss: 0.00167\n",
      "Epoch: 1800, loss: 0.00167\n",
      "Epoch: 1900, loss: 0.00167\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #### YOUR CODE STARTS HERE ####\n",
    "    # pass trainX as input to the lstm network\n",
    "    train_predict = lstm.forward(trainX)\n",
    "    # clear gradients in the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    #calculate loss using criterion function\n",
    "    loss = criterion(train_predict,trainY)\n",
    "    #backpropogate loss\n",
    "    loss.backward()\n",
    "    #### YOUR CODE ENDS HERE ####\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gF0UsfR8yFrO"
   },
   "source": [
    "## Test and Visualize the results. \n",
    "Test the LSTM network by predicting value for testX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "y7-eERYByJ3O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55697155\n"
     ]
    }
   ],
   "source": [
    "lstm.eval()\n",
    "pred = lstm(testX)\n",
    "\n",
    "predicted = pred.data.numpy()\n",
    "print(np.mean(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxBMnRiMapJk"
   },
   "source": [
    "## Question 4:\n",
    "\n",
    "What is the mean of all values predicted by the LSTM network on testX? (select the nearest value)\n",
    "\n",
    "1.   0.2054\n",
    "2.   0.1204\n",
    "3.   0.9742\n",
    "4.   0.5486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL4V_4_2021_questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
